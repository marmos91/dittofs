# DittoFS configuration with S3 backend preparation
# Infrastructure-only config - S3 stores configured via REST API after deployment
#
# Prerequisites:
# 1. Create secrets: kubectl apply -f dittofs_secrets.yaml
#
# After deployment:
# 1. Login: dittofsctl login --server http://localhost:8080
# 2. Create S3 store: dittofsctl store payload add --name s3-content --type s3 \
#    --config '{"bucket":"dittofs-bucket","region":"us-east-1","access_key_id":"...","secret_access_key":"..."}'
# 3. Create share: dittofsctl share create --name s3-share --path /s3 \
#    --metadata-store memory --content-store s3-content
#
apiVersion: dittofs.dittofs.com/v1alpha1
kind: DittoServer
metadata:
  labels:
    app.kubernetes.io/name: dittofs-operator
    app.kubernetes.io/managed-by: kustomize
  name: dittoserver-aws-s3
  namespace: dittofs
spec:
  image: marmos91c/dittofs:latest
  replicas: 1

  # Storage for internal server data
  storage:
    metadataSize: "10Gi"
    contentSize: "10Gi"

  # Identity configuration (required)
  identity:
    jwt:
      secretRef:
        name: dittofs-jwt-secret
        key: secret
    admin:
      username: admin
      passwordSecretRef:
        name: dittofs-admin-secret
        key: password-hash

  # Control plane database
  database:
    type: sqlite
    sqlite:
      path: "/data/controlplane/controlplane.db"

  # WAL-backed cache - larger for S3 workloads
  cache:
    path: "/data/cache"
    size: "2GB"

  # Control plane REST API
  controlPlane:
    port: 8080

  # Metrics enabled for S3 monitoring
  metrics:
    enabled: true
    port: 9090

  # NFS server port
  nfsPort: 12049

  # Service configuration
  service:
    type: ClusterIP

  # Resource configuration for S3 workloads
  resources:
    limits:
      cpu: "2"
      memory: "4Gi"
    requests:
      cpu: "500m"
      memory: "1Gi"
