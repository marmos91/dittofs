---
phase: 33-benchmark-infrastructure
plan: 02
type: execute
wave: 2
depends_on: [33-01]
files_modified:
  - bench/docker-compose.yml
  - bench/configs/dittofs/badger-s3.yaml
  - bench/configs/dittofs/postgres-s3.yaml
  - bench/configs/dittofs/badger-fs.yaml
  - bench/scripts/bootstrap-dittofs.sh
  - bench/configs/ganesha/ganesha.conf
  - bench/configs/rclone/rclone.conf
  - bench/configs/kernel-nfs/exports
  - bench/configs/samba/smb.conf
  - bench/README.md
autonomous: true
requirements: [BENCH-01]

must_haves:
  truths:
    - "Docker Compose has profiles for all systems: dittofs-badger-s3, dittofs-postgres-s3, dittofs-badger-fs, juicefs, ganesha, rclone, kernel-nfs, samba, dittofs-smb"
    - "Only one profile runs at a time (sequential benchmarking, no resource contention)"
    - "Each system has unique NFS/SMB port (DittoFS:12049, Ganesha:22049, kernel-nfs:32049, RClone:42049, JuiceFS:52049)"
    - "All services have Docker healthchecks and resource limits from .env"
    - "DittoFS bootstrap script creates stores, shares, and adapters via dfsctl REST API"
    - "All competitor config files use environment variables for S3/Postgres credentials (not hardcoded)"
    - "README documents complete workflow from prerequisites to running benchmarks"
  artifacts:
    - path: "bench/docker-compose.yml"
      provides: "All service definitions with profiles, healthchecks, resource limits, port mappings"
      min_lines: 150
    - path: "bench/configs/dittofs/badger-s3.yaml"
      provides: "Minimal DittoFS config for BadgerDB metadata + S3 payload"
    - path: "bench/configs/dittofs/postgres-s3.yaml"
      provides: "Minimal DittoFS config for PostgreSQL metadata + S3 payload"
    - path: "bench/configs/dittofs/badger-fs.yaml"
      provides: "Minimal DittoFS config for BadgerDB metadata + filesystem payload"
    - path: "bench/scripts/bootstrap-dittofs.sh"
      provides: "Parameterized script creating stores/shares/adapters per profile via dfsctl"
    - path: "bench/configs/ganesha/ganesha.conf"
      provides: "NFS-Ganesha FSAL_VFS export configuration"
    - path: "bench/configs/rclone/rclone.conf"
      provides: "RClone S3 remote definition for localstack"
    - path: "bench/configs/kernel-nfs/exports"
      provides: "Kernel NFS exports file"
    - path: "bench/configs/samba/smb.conf"
      provides: "Samba share configuration"
    - path: "bench/README.md"
      provides: "Complete workflow guide with ASCII pipeline diagram"
      min_lines: 100
  key_links:
    - from: "bench/docker-compose.yml"
      to: "bench/configs/dittofs/badger-s3.yaml"
      via: "volume mount"
      pattern: "configs/dittofs.*config.yaml"
    - from: "bench/docker-compose.yml"
      to: "bench/scripts/bootstrap-dittofs.sh"
      via: "volume mount"
      pattern: "bootstrap-dittofs.sh.*bootstrap.sh"
    - from: "bench/docker-compose.yml"
      to: "bench/.env.example"
      via: "environment variable interpolation"
      pattern: "\\$\\{BENCH_"
    - from: "bench/scripts/bootstrap-dittofs.sh"
      to: "bench/scripts/lib/common.sh"
      via: "source import"
      pattern: "source.*lib/common.sh"
---

<objective>
Create Docker Compose configuration with all system profiles, DittoFS config files with bootstrap script, competitor configuration files, and comprehensive README.

Purpose: Complete the benchmark infrastructure so that `docker compose --profile <system> up` starts any competitor system ready for benchmarking.
Output: docker-compose.yml, 3 DittoFS configs, bootstrap script, 4 competitor configs, README.
</objective>

<execution_context>
@/Users/marmos91/.claude/get-shit-done/workflows/execute-plan.md
@/Users/marmos91/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/33-benchmark-infrastructure/33-CONTEXT.md
@.planning/phases/33-benchmark-infrastructure/33-RESEARCH.md
@.planning/phases/33-benchmark-infrastructure/33-01-SUMMARY.md

<interfaces>
<!-- From Plan 01 outputs -->

From bench/scripts/lib/common.sh (created in Plan 01):
```bash
log_info()  { echo -e "${GREEN}[INFO]${NC} $*"; }
log_warn()  { echo -e "${YELLOW}[WARN]${NC} $*"; }
log_error() { echo -e "${RED}[ERROR]${NC} $*" >&2; }
die()       { log_error "$@"; exit 1; }
timer_start() { date +%s; }
timer_stop()  { local start="$1"; local end; end=$(date +%s); echo $((end - start)); }
detect_os()   { case "$(uname -s)" in Linux*) echo "linux" ;; Darwin*) echo "macos" ;; esac; }
require_docker_compose_v2()  # validates docker compose v2 is available
wait_healthy()               # polls docker compose ps for healthy status
```

From bench/.env.example (created in Plan 01):
```bash
S3_ENDPOINT=http://localhost:4566
S3_BUCKET=bench
S3_REGION=us-east-1
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test
POSTGRES_USER=bench
POSTGRES_PASSWORD=bench
POSTGRES_DB=bench
DITTOFS_CONTROLPLANE_SECRET=BenchmarkInfrastructureSecret32ch!
BENCH_WAL_ENABLED=true
BENCH_CPU_LIMIT=2
BENCH_MEM_LIMIT=4g
BENCH_CACHE_SIZE=256MB
BENCH_CACHE_SIZE_MB=256
```

From bench/docker/Dockerfile.dittofs (created in Plan 01):
- Builds dfs + dfsctl, EXPOSE 12049 8080 6060
- HEALTHCHECK on :8080/health/ready
- ENTRYPOINT ["/app/dfs"], CMD ["start", "--foreground", "--config", "/config/config.yaml"]

<!-- Existing project pattern for bootstrap -->
From test/smb-conformance/bootstrap.sh:
- Logs in via dfsctl, creates stores, shares, users
- Uses $DFSCTL variable pointing to /app/dfsctl
- Waits for API readiness before bootstrapping
- Uses --server http://localhost:8080 for all dfsctl commands
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Docker Compose, DittoFS configs, and bootstrap script</name>
  <files>
    bench/docker-compose.yml
    bench/configs/dittofs/badger-s3.yaml
    bench/configs/dittofs/postgres-s3.yaml
    bench/configs/dittofs/badger-fs.yaml
    bench/scripts/bootstrap-dittofs.sh
  </files>
  <action>
**bench/docker-compose.yml** — Single file with all profiles per user decision. Use Docker Compose v2 syntax.

**Infrastructure services** (activated via depends_on, not standalone):

1. `localstack` — `localstack/localstack:4.13.1`
   - Profiles: `[dittofs-badger-s3, dittofs-postgres-s3, juicefs, rclone]`
   - Environment: `SERVICES=s3`, `EAGER_SERVICE_LOADING=1`
   - Healthcheck: `curl -sf http://localhost:4566/_localstack/health`
   - Resource limits from env vars

2. `postgres` — `postgres:16-alpine`
   - Profiles: `[dittofs-postgres-s3, juicefs]`
   - Environment: `POSTGRES_USER`, `POSTGRES_PASSWORD`, `POSTGRES_DB` from env
   - Volume: `postgres-data:/var/lib/postgresql/data`
   - Healthcheck: `pg_isready -U ${POSTGRES_USER:-bench}`
   - Resource limits from env vars

**DittoFS services** (3 separate services, one per backend combo):

3. `dittofs-badger-s3`
   - Build: context `..`, dockerfile `bench/docker/Dockerfile.dittofs`
   - Profiles: `[dittofs-badger-s3]`
   - Ports: `12049:12049`, `8080:8080`, `6060:6060`
   - Depends_on: `localstack` (service_healthy)
   - Volumes: `./configs/dittofs/badger-s3.yaml:/config/config.yaml:ro`, `./scripts/bootstrap-dittofs.sh:/app/bootstrap.sh:ro`, `dittofs-data:/data`, `./results:/results`
   - Environment: `DITTOFS_CONTROLPLANE_SECRET` from env
   - Resource limits from env vars

4. `dittofs-postgres-s3` — same pattern as above but:
   - Profiles: `[dittofs-postgres-s3]`
   - Depends_on: `localstack` AND `postgres` (both service_healthy)
   - Volumes: `./configs/dittofs/postgres-s3.yaml:/config/config.yaml:ro` (rest same)

5. `dittofs-badger-fs` — same pattern but:
   - Profiles: `[dittofs-badger-fs]`
   - NO depends_on (no S3 or Postgres needed)
   - Volumes: `./configs/dittofs/badger-fs.yaml:/config/config.yaml:ro` (rest same)

6. `dittofs-smb` — DittoFS for SMB benchmarking:
   - Profiles: `[dittofs-smb]`
   - Ports: `12445:12445`, `8080:8080`, `6060:6060`
   - Uses badger-s3 config (or a dedicated smb config — use badger-s3.yaml for now)
   - Depends_on: `localstack` (service_healthy)

**Competitor services:**

7. `ganesha` — `apnar/nfs-ganesha:latest`
   - Profiles: `[ganesha]`
   - Ports: `22049:2049`
   - Volumes: `./configs/ganesha/ganesha.conf:/etc/ganesha/ganesha.conf:ro`, `ganesha-data:/export`
   - `cap_add: [SYS_ADMIN]`
   - Healthcheck: `showmount -e localhost` (interval=5s, timeout=3s, retries=10, start_period=5s)
   - Resource limits

8. `kernel-nfs` — `erichough/nfs-server:2.2.1`
   - Profiles: `[kernel-nfs]`
   - Ports: `32049:2049`, `32111:111`
   - Volumes: `kernel-nfs-data:/export`
   - Environment: `NFS_EXPORT_0=/export *(rw,no_subtree_check,no_root_squash,fsid=0)`
   - `cap_add: [SYS_ADMIN]`
   - Healthcheck: `showmount -e localhost` (start_period=10s)
   - Resource limits

9. `rclone` — `rclone/rclone:1.73.1`
   - Profiles: `[rclone]`
   - Ports: `42049:42049`
   - Volumes: `./configs/rclone/rclone.conf:/config/rclone/rclone.conf:ro`, `rclone-cache:/tmp/rclone-cache`
   - Command: `serve nfs localstack-s3: --addr 0.0.0.0:42049 --vfs-cache-mode full --vfs-cache-max-size ${BENCH_CACHE_SIZE:-256M} --no-modtime`
   - Depends_on: `localstack` (service_healthy)
   - Healthcheck: `rclone rc noop` (start_period=10s) — if this doesn't work, use TCP check on port 42049
   - Resource limits

10. `juicefs` — `juicedata/mount:ce-v1.3.0`
    - Profiles: `[juicefs]`
    - `privileged: true`
    - Ports: `52049:52049` (will need NFS export — see note in research about JuiceFS NFS complexity)
    - Volumes: `/dev/fuse:/dev/fuse`, `juicefs-cache:/var/jfsCache`
    - Depends_on: `localstack` AND `postgres` (both service_healthy)
    - Command: multi-line shell command that runs `juicefs format` then `juicefs gateway` (see research for exact command)
    - Healthcheck: `curl -sf http://localhost:52049/` (start_period=15s, retries=15)
    - Resource limits

11. `samba` — `dperson/samba:latest`
    - Profiles: `[samba]`
    - Ports: `22445:445`
    - Volumes: `samba-data:/export`
    - Command: `-u "bench;bench" -s "export;/export;yes;no;no;bench" -p`
    - Healthcheck: `smbclient -L localhost -U bench%bench -N` — fallback to `nc -z localhost 445`
    - Resource limits

**Named volumes** section at bottom:
`dittofs-data`, `postgres-data`, `ganesha-data`, `kernel-nfs-data`, `rclone-cache`, `juicefs-cache`, `samba-data`

**DittoFS config YAMLs** — All three configs are minimal (stores/shares/adapters created via bootstrap):

`badger-s3.yaml`:
```yaml
logging:
  level: "INFO"
  format: "text"
  output: "stdout"

server:
  shutdown_timeout: 30s

database:
  type: sqlite
  sqlite:
    path: "/data/controlplane.db"

controlplane:
  port: 8080
  jwt:
    secret: "benchmark-infrastructure-secret-key-32ch"
    access_token_duration: 1h
    refresh_token_duration: 168h
```

`postgres-s3.yaml` — identical to badger-s3.yaml (same minimal config, stores differ in bootstrap).

`badger-fs.yaml` — identical to badger-s3.yaml (same minimal config, stores differ in bootstrap).

Note: The YAML configs are intentionally identical — the only difference between backend combos is in what stores the bootstrap script creates.

**bench/scripts/bootstrap-dittofs.sh** — executable, sources lib/common.sh:
- `#!/usr/bin/env bash` + `set -euo pipefail`
- Source `lib/common.sh` (detect SCRIPT_DIR)
- Accept profile as first argument: `PROFILE="${1:?Usage: bootstrap-dittofs.sh <profile>}"`
- Variables: `DFSCTL="/app/dfsctl"`, `SERVER="http://localhost:8080"`, `ADMIN_PASSWORD="${DITTOFS_CONTROLPLANE_SECRET:-admin}"`
- Wait for API readiness (curl health endpoint with retries)
- Login: `$DFSCTL login --server "$SERVER" --username admin --password "$ADMIN_PASSWORD"`
- Create stores based on profile using case statement:
  - `badger-s3`: metadata=badger (db_path=/data/metadata), payload=s3 (bucket from env, endpoint=http://localstack:4566, force_path_style=true)
  - `postgres-s3`: metadata=postgres (host=postgres, port=5432, user/pass/db from env), payload=s3 (same as above)
  - `badger-fs`: metadata=badger (db_path=/data/metadata), payload=filesystem (path=/data/content)
  - `*`: die with unknown profile
- Create share: `$DFSCTL share create --name /export --metadata default --payload default`
- Create NFS adapter: `$DFSCTL adapter create --type nfs --config '{"port":12049}'` (or SMB adapter if profile indicates SMB)
- Log success with profile name
- Must pass ShellCheck
  </action>
  <verify>
    <automated>
test -f bench/docker-compose.yml && test -f bench/configs/dittofs/badger-s3.yaml && test -f bench/configs/dittofs/postgres-s3.yaml && test -f bench/configs/dittofs/badger-fs.yaml && test -x bench/scripts/bootstrap-dittofs.sh && grep -q "dittofs-badger-s3" bench/docker-compose.yml && grep -q "ganesha" bench/docker-compose.yml && grep -q "kernel-nfs" bench/docker-compose.yml && grep -q "rclone" bench/docker-compose.yml && grep -q "juicefs" bench/docker-compose.yml && grep -q "samba" bench/docker-compose.yml && grep -q "localstack" bench/docker-compose.yml && echo "PASS: Docker Compose and all configs exist" || echo "FAIL"
    </automated>
  </verify>
  <done>
    - docker-compose.yml defines all 11 services (2 infra + 4 DittoFS + 5 competitors)
    - Every service has a profile, healthcheck, and resource limits
    - Unique ports: 12049 (DittoFS NFS), 22049 (Ganesha), 32049 (kernel-nfs), 42049 (RClone), 52049 (JuiceFS), 12445 (DittoFS SMB), 22445 (Samba)
    - 3 DittoFS config YAMLs exist (minimal, stores via bootstrap)
    - bootstrap-dittofs.sh creates stores/shares/adapters per profile via dfsctl
    - All S3/Postgres credentials come from .env (not hardcoded in configs)
  </done>
</task>

<task type="auto">
  <name>Task 2: Create competitor configs and README</name>
  <files>
    bench/configs/ganesha/ganesha.conf
    bench/configs/rclone/rclone.conf
    bench/configs/kernel-nfs/exports
    bench/configs/samba/smb.conf
    bench/README.md
  </files>
  <action>
**bench/configs/ganesha/ganesha.conf** — NFS-Ganesha FSAL_VFS configuration:
```
NFS_CORE_PARAM {
    NFS_Port = 2049;
    NFS_Protocols = 3, 4;
}

EXPORT {
    Export_Id = 1;
    Path = /export;
    Pseudo = /export;
    Access_Type = RW;
    Squash = No_root_squash;
    SecType = sys;
    Transports = TCP;
    Protocols = 3, 4;
    FSAL {
        Name = VFS;
    }
}
```

**bench/configs/rclone/rclone.conf** — RClone S3 remote:
```ini
[localstack-s3]
type = s3
provider = Other
access_key_id = test
secret_access_key = test
endpoint = http://localstack:4566
region = us-east-1
force_path_style = true
```
Note: rclone.conf credentials default to LocalStack values. When using real S3, users should create a custom rclone.conf or the docker-compose command should pass credentials via env vars.

**bench/configs/kernel-nfs/exports** — Kernel NFS exports file:
```
/export *(rw,no_subtree_check,no_root_squash,fsid=0)
```
Note: erichough/nfs-server actually uses NFS_EXPORT_0 env var, so this file is a reference. The docker-compose.yml uses the env var approach.

**bench/configs/samba/smb.conf** — Samba configuration:
```ini
[global]
workgroup = WORKGROUP
server string = DittoFS Benchmark Samba
security = user
map to guest = never
log level = 1

[export]
path = /export
browsable = yes
writable = yes
guest ok = no
valid users = bench
create mask = 0644
directory mask = 0755
```
Note: dperson/samba actually configures via command-line args (`-u` for users, `-s` for shares), so this smb.conf may be used as a volume mount or the docker-compose command approach takes precedence. Include both approaches in docker-compose.yml (command args as primary, config as reference).

**bench/README.md** — Comprehensive workflow guide:

Structure:
1. **Title**: DittoFS Benchmark Suite
2. **Overview**: 2-3 sentences explaining what this suite does (compare DittoFS against 5 competitors)
3. **Quick Start**: 5 steps to run first benchmark (copy .env, check prereqs, build, up, bootstrap)
4. **ASCII Pipeline Diagram**: Shows the benchmark flow
   ```
   Prerequisites Check → Build Images → Start System → Bootstrap → Mount NFS → Run fio → Collect Results → Stop & Clean
   ```
5. **Available Systems**: Table of all profiles with ports, backends, and descriptions
6. **Directory Structure**: Tree showing bench/ layout with descriptions
7. **Configuration**: How to customize .env, resource limits, S3 endpoints
8. **Usage Examples**: Common make commands and docker compose commands
9. **Platform Notes**: Linux vs macOS differences (fio engine, mount options, cache flush)
10. **Port Map**: Table of all port assignments (from research)
11. **Adding a New Competitor**: Brief guide (add service to docker-compose.yml, create config, add profile)
12. **Troubleshooting**: Common issues (stale mounts, port conflicts, Docker Desktop limitations)
13. **Related Phases**: Links to Phase 34 (workloads), 35 (competitor setup), 36 (orchestrator), 37 (analysis), 38 (profiling)

Keep README focused and practical. No marketing language. Include actual commands users can copy-paste.
  </action>
  <verify>
    <automated>
test -f bench/configs/ganesha/ganesha.conf && test -f bench/configs/rclone/rclone.conf && test -f bench/configs/kernel-nfs/exports && test -f bench/configs/samba/smb.conf && test -f bench/README.md && grep -q "FSAL" bench/configs/ganesha/ganesha.conf && grep -q "localstack-s3" bench/configs/rclone/rclone.conf && grep -q "Quick Start" bench/README.md && echo "PASS: All competitor configs and README exist" || echo "FAIL"
    </automated>
  </verify>
  <done>
    - ganesha.conf configures FSAL_VFS export on /export with NFSv3+v4
    - rclone.conf defines S3 remote pointing to LocalStack
    - kernel-nfs exports file exports /export with rw,no_root_squash
    - smb.conf configures [export] share with bench user
    - README has Quick Start, pipeline diagram, system table, port map, troubleshooting
    - All configs use /export path for consistency across systems
  </done>
</task>

</tasks>

<verification>
1. Validate docker-compose.yml syntax: `docker compose -f bench/docker-compose.yml config --profiles dittofs-badger-s3 2>&1 | head -5` (should not error)
2. Verify all profiles exist: grep for each profile name in docker-compose.yml
3. Verify port uniqueness: grep all port mappings, ensure no duplicates
4. Verify healthchecks: every service (except infrastructure) has a healthcheck block
5. Verify resource limits: every benchmarked service has deploy.resources.limits
6. Verify bootstrap script handles all 3 DittoFS profiles
7. Verify README completeness: has Quick Start, port map, and troubleshooting sections
8. Run ShellCheck on bootstrap-dittofs.sh if available: `shellcheck bench/scripts/bootstrap-dittofs.sh`
</verification>

<success_criteria>
- `docker compose --profile dittofs-badger-s3 config` validates successfully
- All 9 profiles are defined (3 DittoFS NFS + 1 DittoFS SMB + 5 competitors)
- Each system exports /export on its unique port
- bootstrap-dittofs.sh handles badger-s3, postgres-s3, badger-fs profiles
- All competitor configs are ready to use
- README guides a new user from zero to running their first benchmark
</success_criteria>

<output>
After completion, create `.planning/phases/33-benchmark-infrastructure/33-02-SUMMARY.md`
</output>
