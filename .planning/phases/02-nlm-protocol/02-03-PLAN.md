---
phase: 02-nlm-protocol
plan: 03
type: execute
wave: 3
depends_on: ["02-02"]
files_modified:
  - internal/protocol/nlm/blocking/queue.go
  - internal/protocol/nlm/blocking/waiter.go
  - internal/protocol/nlm/callback/client.go
  - internal/protocol/nlm/callback/granted.go
  - internal/protocol/nlm/handlers/lock.go
  - internal/protocol/nlm/handlers/cancel.go
  - internal/protocol/nlm/handlers/granted.go
  - internal/protocol/nlm/metrics.go
  - pkg/metadata/service.go
autonomous: true

must_haves:
  truths:
    - "Blocking lock requests return NLM4_BLOCKED and queue the waiter"
    - "When lock is released, queued waiters are processed in FIFO order"
    - "NLM_GRANTED callback sent to client when blocked lock becomes available"
    - "Callback failure releases the lock immediately (no orphaned grants)"
    - "NLM_CANCEL removes waiter from queue and returns NLM4_GRANTED"
    - "Queue full returns NLM4_DENIED_NOLOCKS"
    - "Prometheus metrics track NLM operations"
  artifacts:
    - path: "internal/protocol/nlm/blocking/queue.go"
      provides: "Per-file blocking lock queue"
      exports: ["BlockingQueue", "NewBlockingQueue"]
    - path: "internal/protocol/nlm/blocking/waiter.go"
      provides: "Waiter entry with callback info"
      exports: ["Waiter"]
    - path: "internal/protocol/nlm/callback/client.go"
      provides: "TCP callback client for NLM_GRANTED"
      exports: ["SendGrantedCallback"]
    - path: "internal/protocol/nlm/metrics.go"
      provides: "NLM Prometheus metrics"
      exports: ["Metrics", "NewMetrics"]
  key_links:
    - from: "internal/protocol/nlm/handlers/lock.go"
      to: "internal/protocol/nlm/blocking"
      via: "queue waiter on conflict"
      pattern: "blockingQueue.*Enqueue"
    - from: "internal/protocol/nlm/callback/granted.go"
      to: "internal/protocol/nlm/callback/client.go"
      via: "send callback"
      pattern: "SendGrantedCallback"
    - from: "pkg/metadata/service.go"
      to: "internal/protocol/nlm/blocking"
      via: "notify on unlock"
      pattern: "ProcessRelease"
---

<objective>
Implement blocking lock queue and NLM_GRANTED callback mechanism.

Purpose: Enable NFSv3 clients to use blocking (waiting) locks. When a lock request conflicts, the client waits and receives an NLM_GRANTED callback when the lock becomes available.

Output:
- Per-file blocking lock queue with configurable size limit
- NLM_GRANTED callback client with 5-second timeout
- Integration with unlock path to process waiters
- NLM-specific Prometheus metrics
</objective>

<execution_context>
@/Users/marmos91/.claude/get-shit-done/workflows/execute-plan.md
@/Users/marmos91/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-nlm-protocol/02-CONTEXT.md
@.planning/phases/02-nlm-protocol/02-RESEARCH.md
@.planning/phases/02-nlm-protocol/02-01-SUMMARY.md
@.planning/phases/02-nlm-protocol/02-02-SUMMARY.md
@internal/protocol/nlm/handlers/lock.go
@internal/protocol/nlm/handlers/cancel.go
@pkg/metadata/service.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create blocking lock queue infrastructure</name>
  <files>
    internal/protocol/nlm/blocking/waiter.go
    internal/protocol/nlm/blocking/queue.go
  </files>
  <action>
Create the blocking lock queue infrastructure per CONTEXT.md decisions:

1. Create internal/protocol/nlm/blocking/waiter.go:
```go
package blocking

import (
    "sync"
    "time"

    "github.com/marmos91/dittofs/pkg/metadata/lock"
)

// Waiter represents a pending blocking lock request.
type Waiter struct {
    // Lock is the requested lock
    Lock *lock.EnhancedLock

    // Cookie is the client's opaque cookie (echoed in callback)
    Cookie []byte

    // Exclusive is whether the lock is exclusive
    Exclusive bool

    // CallbackAddr is the client's callback address (IP:port)
    CallbackAddr string

    // CallbackProg is the client's callback program number (NLM)
    CallbackProg uint32

    // CallbackVers is the callback program version
    CallbackVers uint32

    // CallerName is the client hostname from the lock request
    CallerName string

    // Svid is the client's process ID
    Svid int32

    // OH is the client's owner handle (opaque)
    OH []byte

    // FileHandle is the file this lock is for
    FileHandle []byte

    // QueuedAt is when this waiter was queued
    QueuedAt time.Time

    // Cancelled indicates if this waiter has been cancelled
    Cancelled bool

    // mu protects the Cancelled field
    mu sync.Mutex
}

// IsCancelled returns true if this waiter has been cancelled.
func (w *Waiter) IsCancelled() bool {
    w.mu.Lock()
    defer w.mu.Unlock()
    return w.Cancelled
}

// Cancel marks this waiter as cancelled.
func (w *Waiter) Cancel() {
    w.mu.Lock()
    defer w.mu.Unlock()
    w.Cancelled = true
}
```

2. Create internal/protocol/nlm/blocking/queue.go:
```go
package blocking

import (
    "sync"

    "github.com/marmos91/dittofs/pkg/metadata/lock"
)

// ErrQueueFull is returned when the per-file queue is at capacity.
var ErrQueueFull = errors.New("blocking queue full")

// BlockingQueue manages per-file queues of waiting lock requests.
type BlockingQueue struct {
    mu       sync.RWMutex
    queues   map[string][]*Waiter // fileHandle -> waiters (slice, not channel)
    maxQueue int                  // Per-file limit (e.g., 100)
}

// NewBlockingQueue creates a new blocking queue with the given per-file limit.
func NewBlockingQueue(maxPerFile int) *BlockingQueue {
    return &BlockingQueue{
        queues:   make(map[string][]*Waiter),
        maxQueue: maxPerFile,
    }
}

// Enqueue adds a waiter to the queue for a file.
// Returns ErrQueueFull if the per-file limit is reached.
func (bq *BlockingQueue) Enqueue(fileHandle string, waiter *Waiter) error {
    bq.mu.Lock()
    defer bq.mu.Unlock()

    queue := bq.queues[fileHandle]
    if len(queue) >= bq.maxQueue {
        return ErrQueueFull
    }

    waiter.QueuedAt = time.Now()
    bq.queues[fileHandle] = append(queue, waiter)
    return nil
}

// Cancel removes a waiter matching the given owner and range.
// Returns true if a waiter was found and cancelled.
func (bq *BlockingQueue) Cancel(fileHandle string, ownerID string, offset, length uint64) bool {
    bq.mu.Lock()
    defer bq.mu.Unlock()

    queue := bq.queues[fileHandle]
    for i, w := range queue {
        if w.Lock.Owner.OwnerID == ownerID &&
           w.Lock.Offset == offset &&
           w.Lock.Length == length {
            // Mark as cancelled
            w.Cancel()
            // Remove from queue
            bq.queues[fileHandle] = append(queue[:i], queue[i+1:]...)
            if len(bq.queues[fileHandle]) == 0 {
                delete(bq.queues, fileHandle)
            }
            return true
        }
    }
    return false
}

// GetWaiters returns a copy of all waiters for a file.
// Used by ProcessRelease to try granting locks.
func (bq *BlockingQueue) GetWaiters(fileHandle string) []*Waiter {
    bq.mu.RLock()
    defer bq.mu.RUnlock()

    queue := bq.queues[fileHandle]
    if len(queue) == 0 {
        return nil
    }

    // Return a copy
    result := make([]*Waiter, len(queue))
    copy(result, queue)
    return result
}

// RemoveWaiter removes a specific waiter from the queue.
// Called after successfully granting a lock.
func (bq *BlockingQueue) RemoveWaiter(fileHandle string, waiter *Waiter) {
    bq.mu.Lock()
    defer bq.mu.Unlock()

    queue := bq.queues[fileHandle]
    for i, w := range queue {
        if w == waiter {
            bq.queues[fileHandle] = append(queue[:i], queue[i+1:]...)
            if len(bq.queues[fileHandle]) == 0 {
                delete(bq.queues, fileHandle)
            }
            return
        }
    }
}
```
  </action>
  <verify>
Run: `go build ./internal/protocol/nlm/blocking/...` - compiles without errors
Run: `go vet ./internal/protocol/nlm/blocking/...` - no issues
  </verify>
  <done>
Blocking queue infrastructure exists with Waiter type and BlockingQueue with per-file limits.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement NLM_GRANTED callback client</name>
  <files>
    internal/protocol/nlm/callback/client.go
    internal/protocol/nlm/callback/granted.go
    internal/protocol/nlm/handlers/granted.go
  </files>
  <action>
Create the callback client for NLM_GRANTED notifications per CONTEXT.md:

1. Create internal/protocol/nlm/callback/client.go:
```go
package callback

import (
    "bytes"
    "context"
    "fmt"
    "net"
    "time"

    "github.com/marmos91/dittofs/internal/protocol/nfs/rpc"
    "github.com/marmos91/dittofs/internal/protocol/nlm"
    nlm_xdr "github.com/marmos91/dittofs/internal/protocol/nlm/xdr"
)

const (
    // CallbackTimeout is the timeout for NLM_GRANTED callbacks per CONTEXT.md
    CallbackTimeout = 5 * time.Second
)

// SendGrantedCallback sends an NLM_GRANTED callback to a client.
// Returns nil on success, error if callback failed.
// Per CONTEXT.md: fresh TCP connection for each callback, 5s timeout.
func SendGrantedCallback(
    ctx context.Context,
    addr string,
    prog uint32,
    vers uint32,
    args *nlm.NLM4GrantedArgs,
) error {
    // Create TCP connection with timeout
    dialer := net.Dialer{Timeout: CallbackTimeout}
    conn, err := dialer.DialContext(ctx, "tcp", addr)
    if err != nil {
        return fmt.Errorf("dial callback address %s: %w", addr, err)
    }
    defer conn.Close()

    // Set read/write deadline
    deadline := time.Now().Add(CallbackTimeout)
    if err := conn.SetDeadline(deadline); err != nil {
        return fmt.Errorf("set deadline: %w", err)
    }

    // Encode NLM_GRANTED args
    var argsBuf bytes.Buffer
    if err := nlm_xdr.EncodeNLM4GrantedArgs(&argsBuf, args); err != nil {
        return fmt.Errorf("encode granted args: %w", err)
    }

    // Build RPC call message
    // XID can be any unique value - use current time nanoseconds
    xid := uint32(time.Now().UnixNano() & 0xFFFFFFFF)

    callMsg, err := rpc.MakeCallMessage(xid, prog, vers, nlm.NLMProcGranted, argsBuf.Bytes())
    if err != nil {
        return fmt.Errorf("make call message: %w", err)
    }

    // Send the call
    if _, err := conn.Write(callMsg); err != nil {
        return fmt.Errorf("write call: %w", err)
    }

    // Read and validate response (we don't care about the result per CONTEXT.md,
    // but we need to wait for it to confirm delivery)
    // Read fragment header (4 bytes)
    var headerBuf [4]byte
    if _, err := conn.Read(headerBuf[:]); err != nil {
        return fmt.Errorf("read reply header: %w", err)
    }

    // Parse fragment length
    header := uint32(headerBuf[0])<<24 | uint32(headerBuf[1])<<16 |
              uint32(headerBuf[2])<<8 | uint32(headerBuf[3])
    fragLen := header & 0x7FFFFFFF

    // Read reply body (just discard - we don't care about status per CONTEXT.md)
    replyBuf := make([]byte, fragLen)
    if _, err := conn.Read(replyBuf); err != nil {
        return fmt.Errorf("read reply body: %w", err)
    }

    return nil
}
```

2. Create internal/protocol/nlm/callback/granted.go:
```go
package callback

import (
    "context"

    "github.com/marmos91/dittofs/internal/logger"
    "github.com/marmos91/dittofs/internal/protocol/nlm"
    "github.com/marmos91/dittofs/internal/protocol/nlm/blocking"
    "github.com/marmos91/dittofs/pkg/metadata/lock"
)

// ProcessGrantedCallback sends NLM_GRANTED callback to a waiter.
// If callback fails, releases the lock immediately per CONTEXT.md.
// Returns true if callback succeeded, false if it failed.
func ProcessGrantedCallback(
    ctx context.Context,
    waiter *blocking.Waiter,
    lm *lock.Manager,
) bool {
    // Check if cancelled while we were processing
    if waiter.IsCancelled() {
        logger.Debug("Skipping callback for cancelled waiter",
            "owner", waiter.Lock.Owner.OwnerID)
        return false
    }

    // Build NLM_GRANTED args
    args := &nlm.NLM4GrantedArgs{
        Cookie:    waiter.Cookie,
        Exclusive: waiter.Exclusive,
        Lock: nlm.NLM4Lock{
            CallerName: waiter.CallerName,
            FH:         waiter.FileHandle,
            OH:         waiter.OH,
            Svid:       waiter.Svid,
            Offset:     waiter.Lock.Offset,
            Length:     waiter.Lock.Length,
        },
    }

    // Send callback
    err := SendGrantedCallback(ctx, waiter.CallbackAddr, waiter.CallbackProg,
                               waiter.CallbackVers, args)
    if err != nil {
        logger.Warn("NLM_GRANTED callback failed, releasing lock",
            "error", err,
            "addr", waiter.CallbackAddr,
            "owner", waiter.Lock.Owner.OwnerID)

        // Per CONTEXT.md: release lock immediately if callback fails
        handleKey := string(waiter.Lock.FileHandle)
        _ = lm.RemoveEnhancedLock(handleKey, waiter.Lock.Owner,
                                  waiter.Lock.Offset, waiter.Lock.Length)
        return false
    }

    logger.Debug("NLM_GRANTED callback succeeded",
        "addr", waiter.CallbackAddr,
        "owner", waiter.Lock.Owner.OwnerID)
    return true
}
```

3. Create internal/protocol/nlm/handlers/granted.go:
   - Handler for NLM_GRANTED procedure (receives responses to our callbacks)
   - Most NLM servers ignore the response, but we need to handle it
   - Simply return NLM4_GRANTED (acknowledge receipt)
  </action>
  <verify>
Run: `go build ./internal/protocol/nlm/callback/...` - compiles without errors
Run: `go build ./internal/protocol/nlm/handlers/...` - compiles with granted.go
  </verify>
  <done>
NLM_GRANTED callback client implemented with 5-second timeout and lock release on failure.
  </done>
</task>

<task type="auto">
  <name>Task 3: Integrate blocking queue with lock/unlock handlers and add metrics</name>
  <files>
    internal/protocol/nlm/handlers/lock.go
    internal/protocol/nlm/handlers/cancel.go
    pkg/metadata/service.go
    internal/protocol/nlm/metrics.go
  </files>
  <action>
1. Update internal/protocol/nlm/handlers/lock.go to use blocking queue:
   - If block=true and lock conflicts:
     a. Create Waiter with callback info from request
     b. Extract callback address from client (use connection remote addr + callback port from request if provided, else use standard NLM port)
     c. Enqueue waiter
     d. If queue full: return NLM4_DENIED_NOLOCKS
     e. Else: return NLM4_BLOCKED (client will wait for callback)

2. Update internal/protocol/nlm/handlers/cancel.go:
   - Call blockingQueue.Cancel() to find and remove the waiter
   - Return NLM4_GRANTED (always succeeds per CONTEXT.md)

3. Update pkg/metadata/service.go unlock path:
   - After releasing a lock, call ProcessRelease on the blocking queue
   - ProcessRelease iterates waiters in FIFO order:
     a. For each waiter, try to acquire the lock
     b. If success, send NLM_GRANTED callback (via goroutine)
     c. Remove waiter from queue
     d. If callback fails, lock already released by ProcessGrantedCallback
     e. Continue to next waiter if current one failed

4. Add blocking queue to NLM handler struct and wire up.

5. Create internal/protocol/nlm/metrics.go:
```go
package nlm

import (
    "github.com/prometheus/client_golang/prometheus"
)

// Metrics tracks NLM-specific metrics.
type Metrics struct {
    // RequestsTotal counts NLM requests by procedure and status
    RequestsTotal *prometheus.CounterVec

    // RequestDuration tracks latency distribution
    RequestDuration *prometheus.HistogramVec

    // BlockingQueueSize tracks current queue depth per file
    BlockingQueueSize prometheus.Gauge

    // CallbacksTotal counts NLM_GRANTED callbacks by result
    CallbacksTotal *prometheus.CounterVec

    // CallbackDuration tracks callback latency
    CallbackDuration prometheus.Histogram
}

// NewMetrics creates NLM metrics with nlm_ prefix.
func NewMetrics(reg prometheus.Registerer) *Metrics {
    m := &Metrics{
        RequestsTotal: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "nlm_requests_total",
                Help: "Total NLM requests by procedure and status",
            },
            []string{"procedure", "status"},
        ),
        RequestDuration: prometheus.NewHistogramVec(
            prometheus.HistogramOpts{
                Name:    "nlm_request_duration_seconds",
                Help:    "NLM request duration in seconds",
                Buckets: prometheus.DefBuckets,
            },
            []string{"procedure"},
        ),
        BlockingQueueSize: prometheus.NewGauge(
            prometheus.GaugeOpts{
                Name: "nlm_blocking_queue_size",
                Help: "Current number of waiting lock requests",
            },
        ),
        CallbacksTotal: prometheus.NewCounterVec(
            prometheus.CounterOpts{
                Name: "nlm_callbacks_total",
                Help: "Total NLM_GRANTED callbacks by result",
            },
            []string{"result"}, // "success", "failed", "cancelled"
        ),
        CallbackDuration: prometheus.NewHistogram(
            prometheus.HistogramOpts{
                Name:    "nlm_callback_duration_seconds",
                Help:    "NLM_GRANTED callback duration in seconds",
                Buckets: prometheus.DefBuckets,
            },
        ),
    }

    // Register all metrics
    reg.MustRegister(m.RequestsTotal, m.RequestDuration,
                     m.BlockingQueueSize, m.CallbacksTotal, m.CallbackDuration)

    return m
}
```

6. Wire metrics into handlers - record on each request completion.
  </action>
  <verify>
Run: `go build ./internal/protocol/nlm/...` - compiles
Run: `go build ./pkg/metadata/...` - compiles
Run: `go test ./...` - all tests pass
  </verify>
  <done>
Blocking lock queue integrated with lock/unlock handlers. NLM_GRANTED callbacks sent on lock release. NLM Prometheus metrics registered.
  </done>
</task>

</tasks>

<verification>
Overall verification for Plan 02-03:

1. Blocking queue infrastructure:
   - `ls internal/protocol/nlm/blocking/` shows queue.go, waiter.go
   - `go build ./internal/protocol/nlm/blocking/...` compiles

2. Callback client:
   - `ls internal/protocol/nlm/callback/` shows client.go, granted.go
   - `go build ./internal/protocol/nlm/callback/...` compiles

3. Integration:
   - `grep "blockingQueue" internal/protocol/nlm/handlers/lock.go` shows queue usage
   - `grep "ProcessRelease" pkg/metadata/service.go` shows unlock integration

4. Metrics:
   - `grep "nlm_requests_total" internal/protocol/nlm/metrics.go` shows metrics

5. Full test suite:
   - `go test ./...` passes
</verification>

<success_criteria>
- Blocking lock requests (block=true) return NLM4_BLOCKED and queue waiter
- Queue full returns NLM4_DENIED_NOLOCKS
- Lock release processes queued waiters in FIFO order
- NLM_GRANTED callback sent with 5-second timeout
- Callback failure releases the lock immediately
- NLM_CANCEL removes waiter from queue
- Prometheus metrics track NLM operations with nlm_* prefix
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/02-nlm-protocol/02-03-SUMMARY.md`
</output>
