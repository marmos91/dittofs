---
phase: 05-status-conditions-and-lifecycle
plan: 03
type: execute
wave: 2
depends_on: ["05-01", "05-02"]
files_modified:
  - k8s/dittofs-operator/internal/controller/dittoserver_controller.go
  - k8s/dittofs-operator/cmd/main.go
autonomous: true

must_haves:
  truths:
    - "kubectl describe dittofs shows events for state changes (Created, Updated, Deleting)"
    - "kubectl describe dittofs shows warning events for errors and Percona not ready"
    - "DittoFS pod has HTTP-based liveness probe at /health on API port"
    - "DittoFS pod has HTTP-based readiness probe at /health/ready on API port"
    - "DittoFS pod has startup probe with 150-second timeout"
    - "Pod has preStop hook with 5-second sleep for connection draining"
  artifacts:
    - path: "k8s/dittofs-operator/internal/controller/dittoserver_controller.go"
      provides: "EventRecorder usage and HTTP-based probes"
      contains: "r.Recorder.Event"
    - path: "k8s/dittofs-operator/cmd/main.go"
      provides: "EventRecorder wiring to reconciler"
      contains: "GetEventRecorderFor"
  key_links:
    - from: "cmd/main.go"
      to: "dittoserver_controller.go"
      via: "Recorder field initialization"
      pattern: "Recorder.*GetEventRecorderFor"
    - from: "dittoserver_controller.go"
      to: "corev1.EventType"
      via: "Event emission calls"
      pattern: "corev1\\.EventType(Normal|Warning)"
---

<objective>
Implement Kubernetes events, HTTP health probes, and graceful shutdown for DittoFS operator.

Purpose: Enable operational debugging via events (R5.3), proper health monitoring with HTTP probes that check actual DittoFS health endpoints (R5.4), and graceful shutdown via preStop hook (R5.5).

Output: EventRecorder wired in reconciler emitting events for state changes and errors. HTTP-based probes replacing current TCP probes. PreStop lifecycle hook for connection draining.
</objective>

<execution_context>
@/Users/marmos91/.claude/get-shit-done/workflows/execute-plan.md
@/Users/marmos91/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-status-conditions-and-lifecycle/05-RESEARCH.md
@.planning/phases/05-status-conditions-and-lifecycle/05-01-PLAN.md
@.planning/phases/05-status-conditions-and-lifecycle/05-02-PLAN.md
@k8s/dittofs-operator/internal/controller/dittoserver_controller.go
@k8s/dittofs-operator/cmd/main.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire EventRecorder into reconciler via main.go</name>
  <files>
    k8s/dittofs-operator/internal/controller/dittoserver_controller.go
    k8s/dittofs-operator/cmd/main.go
  </files>
  <action>
1. In `dittoserver_controller.go`, add the Recorder field to DittoServerReconciler struct:

```go
import (
    // ... existing imports ...
    "k8s.io/client-go/tools/record"
)

// DittoServerReconciler reconciles a DittoServer object
type DittoServerReconciler struct {
    client.Client
    Scheme   *runtime.Scheme
    Recorder record.EventRecorder
}
```

2. In `cmd/main.go`, update the reconciler initialization to include the EventRecorder. Find the section where DittoServerReconciler is created and update it:

```go
    if err := (&controller.DittoServerReconciler{
        Client:   mgr.GetClient(),
        Scheme:   mgr.GetScheme(),
        Recorder: mgr.GetEventRecorderFor("dittoserver-controller"),
    }).SetupWithManager(mgr); err != nil {
        setupLog.Error(err, "unable to create controller", "controller", "DittoServer")
        os.Exit(1)
    }
```

3. Add the import for record package in main.go if not present (check if it's already there via client-go):
```go
import (
    // ... existing imports ...
    // Note: record is often implicitly available via controller-runtime
    // but ensure "k8s.io/client-go/tools/record" is in imports
)
```

Note: The RBAC marker for events already exists in the controller file:
```go
// +kubebuilder:rbac:groups="",resources=events,verbs=create;patch
```
Verify this marker is present; if not, add it.
  </action>
  <verify>
```bash
cd /Users/marmos91/Projects/dittofs/k8s/dittofs-operator && go build ./...
```
Build succeeds without import errors.
  </verify>
  <done>
- DittoServerReconciler has Recorder field of type record.EventRecorder
- main.go passes mgr.GetEventRecorderFor("dittoserver-controller") to reconciler
- RBAC marker for events exists
  </done>
</task>

<task type="auto">
  <name>Task 2: Add event emission throughout reconciliation lifecycle</name>
  <files>
    k8s/dittofs-operator/internal/controller/dittoserver_controller.go
  </files>
  <action>
Add event emission at key points in the reconciliation. Follow "moderate verbosity" - emit for errors, state changes, not every reconciliation.

1. In the finalizer addition section (after adding finalizer), emit an event:
```go
    // After: controllerutil.AddFinalizer(dittoServer, finalizerName)
    // Before: if err := r.Update(ctx, dittoServer); err != nil { ... }
    r.Recorder.Event(dittoServer, corev1.EventTypeNormal, "Created",
        "DittoServer created, finalizer added")
```

2. In handleDeletion, emit events at key points:
```go
    // After setting Phase to "Deleting"
    r.Recorder.Event(dittoServer, corev1.EventTypeNormal, "Deleting",
        "DittoServer is being deleted, cleaning up resources")

    // After timeout force removal
    r.Recorder.Event(dittoServer, corev1.EventTypeWarning, "CleanupTimeout",
        fmt.Sprintf("Cleanup timeout exceeded (%v), forcing finalizer removal", cleanupTimeout))
```

3. In performCleanup, emit events for Percona handling:
```go
    // When deleting Percona (after successful delete)
    r.Recorder.Eventf(dittoServer, corev1.EventTypeWarning, "PerconaDeleted",
        "PerconaPGCluster %s deleted (deleteWithServer=true)", clusterName)

    // When orphaning Percona (after successful orphan)
    r.Recorder.Eventf(dittoServer, corev1.EventTypeNormal, "PerconaOrphaned",
        "PerconaPGCluster %s orphaned and will be preserved", clusterName)
```

4. In the Percona readiness check (where we wait for Percona), emit a warning when not ready:
```go
    // In the section: if !percona.IsReady(pgCluster) { ... }
    // Before: return ctrl.Result{RequeueAfter: 10 * time.Second}, nil
    r.Recorder.Eventf(dittoServer, corev1.EventTypeWarning, "PerconaNotReady",
        "Waiting for PostgreSQL cluster %s (state: %s)", percona.ClusterName(dittoServer.Name), percona.GetState(pgCluster))
```

5. In reconcileConfigMap, emit event on config update (detect change):
```go
    // Modify reconcileConfigMap to detect if config changed
    // After CreateOrUpdate, check if operation was "updated"
    op, err := controllerutil.CreateOrUpdate(ctx, r.Client, configMap, func() error {
        // ... existing logic ...
    })
    if err != nil {
        return err
    }
    if op == controllerutil.OperationResultUpdated {
        // Need to pass dittoServer to this function or emit event in caller
        // For simplicity, we'll emit this in Reconcile after calling reconcileConfigMap
    }
```

Actually, for cleaner code, add a helper that emits events after successful reconciliation steps. Add this after the status update section, before returning:

```go
    // Emit event if this is a new generation (config changed)
    // Check if we're seeing this generation for the first time
    if dittoServer.Generation > 1 && dittoServerCopy.Status.ObservedGeneration == dittoServer.Generation {
        // This is an update, not initial creation
        r.Recorder.Event(dittoServer, corev1.EventTypeNormal, "ConfigUpdated",
            fmt.Sprintf("Configuration updated, pods will restart (hash: %s)", configHash[:8]))
    }
```

6. Add event on error paths. In each error return, add event before returning:
```go
    // Example in reconcileStatefulSet error handler:
    if err := r.reconcileStatefulSet(...); err != nil {
        r.Recorder.Eventf(dittoServer, corev1.EventTypeWarning, "ReconcileFailed",
            "Failed to reconcile StatefulSet: %v", err)
        logger.Error(err, "Failed to reconcile StatefulSet")
        return ctrl.Result{}, err
    }
```

Apply similar pattern to other error handlers (reconcileConfigMap, reconcileServices, etc.).
  </action>
  <verify>
```bash
cd /Users/marmos91/Projects/dittofs/k8s/dittofs-operator && go build ./... && go test ./... -v
```
Build and tests pass.
  </verify>
  <done>
- Event emitted on: Created, Deleting, CleanupTimeout, PerconaDeleted, PerconaOrphaned, PerconaNotReady, ConfigUpdated
- Warning events for: errors, timeouts, Percona not ready, cleanup issues
- Normal events for: creation, config updates, successful cleanup
- Events use corev1.EventTypeNormal or corev1.EventTypeWarning appropriately
  </done>
</task>

<task type="auto">
  <name>Task 3: Replace TCP probes with HTTP probes and add startup probe and preStop hook</name>
  <files>
    k8s/dittofs-operator/internal/controller/dittoserver_controller.go
  </files>
  <action>
In reconcileStatefulSet, replace the current TCP-based probes with HTTP-based probes and add startup probe and preStop lifecycle hook.

Find the container definition in reconcileStatefulSet and update:

1. Replace LivenessProbe (currently TCP to NFS port) with HTTP to /health on API port:
```go
LivenessProbe: &corev1.Probe{
    ProbeHandler: corev1.ProbeHandler{
        HTTPGet: &corev1.HTTPGetAction{
            Path: "/health",
            Port: intstr.FromInt32(getAPIPort(dittoServer)),
        },
    },
    InitialDelaySeconds: 15,
    PeriodSeconds:       10,
    TimeoutSeconds:      5,
    SuccessThreshold:    1,
    FailureThreshold:    3,
},
```

2. Replace ReadinessProbe (currently TCP to NFS port) with HTTP to /health/ready on API port:
```go
ReadinessProbe: &corev1.Probe{
    ProbeHandler: corev1.ProbeHandler{
        HTTPGet: &corev1.HTTPGetAction{
            Path: "/health/ready",
            Port: intstr.FromInt32(getAPIPort(dittoServer)),
        },
    },
    InitialDelaySeconds: 10,
    PeriodSeconds:       5,
    TimeoutSeconds:      5,
    SuccessThreshold:    1,
    FailureThreshold:    3,
},
```

3. Add StartupProbe (allows slow startup, 30 failures * 5s = 150s max):
```go
StartupProbe: &corev1.Probe{
    ProbeHandler: corev1.ProbeHandler{
        HTTPGet: &corev1.HTTPGetAction{
            Path: "/health",
            Port: intstr.FromInt32(getAPIPort(dittoServer)),
        },
    },
    InitialDelaySeconds: 0,
    PeriodSeconds:       5,
    TimeoutSeconds:      5,
    SuccessThreshold:    1,
    FailureThreshold:    30, // 30 * 5s = 150s max startup time
},
```

4. Add Lifecycle with PreStop hook for graceful shutdown:
```go
Lifecycle: &corev1.Lifecycle{
    PreStop: &corev1.LifecycleHandler{
        Exec: &corev1.ExecAction{
            Command: []string{"/bin/sh", "-c", "sleep 5"},
        },
    },
},
```

The complete container spec should look like:
```go
Containers: []corev1.Container{
    {
        Name:            "dittofs",
        Image:           dittoServer.Spec.Image,
        Command:         []string{"/app/dittofs"},
        Args:            []string{"start", "--config", "/config/config.yaml"},
        VolumeMounts:    volumeMounts,
        Resources:       dittoServer.Spec.Resources,
        SecurityContext: dittoServer.Spec.SecurityContext,
        Ports:           buildContainerPorts(dittoServer),
        Env:             envVars,
        LivenessProbe: &corev1.Probe{
            ProbeHandler: corev1.ProbeHandler{
                HTTPGet: &corev1.HTTPGetAction{
                    Path: "/health",
                    Port: intstr.FromInt32(getAPIPort(dittoServer)),
                },
            },
            InitialDelaySeconds: 15,
            PeriodSeconds:       10,
            TimeoutSeconds:      5,
            SuccessThreshold:    1,
            FailureThreshold:    3,
        },
        ReadinessProbe: &corev1.Probe{
            ProbeHandler: corev1.ProbeHandler{
                HTTPGet: &corev1.HTTPGetAction{
                    Path: "/health/ready",
                    Port: intstr.FromInt32(getAPIPort(dittoServer)),
                },
            },
            InitialDelaySeconds: 10,
            PeriodSeconds:       5,
            TimeoutSeconds:      5,
            SuccessThreshold:    1,
            FailureThreshold:    3,
        },
        StartupProbe: &corev1.Probe{
            ProbeHandler: corev1.ProbeHandler{
                HTTPGet: &corev1.HTTPGetAction{
                    Path: "/health",
                    Port: intstr.FromInt32(getAPIPort(dittoServer)),
                },
            },
            InitialDelaySeconds: 0,
            PeriodSeconds:       5,
            TimeoutSeconds:      5,
            SuccessThreshold:    1,
            FailureThreshold:    30,
        },
        Lifecycle: &corev1.Lifecycle{
            PreStop: &corev1.LifecycleHandler{
                Exec: &corev1.ExecAction{
                    Command: []string{"/bin/sh", "-c", "sleep 5"},
                },
            },
        },
    },
},
```

Note: Remove the existing TCP-based probes - they're being replaced entirely.
  </action>
  <verify>
```bash
cd /Users/marmos91/Projects/dittofs/k8s/dittofs-operator && go build ./... && go test ./... -v
```
Build and tests pass.
  </verify>
  <done>
- LivenessProbe: HTTP GET /health on API port, 15s initial delay, 10s period
- ReadinessProbe: HTTP GET /health/ready on API port, 10s initial delay, 5s period
- StartupProbe: HTTP GET /health on API port, 150s max startup (30 failures * 5s)
- PreStop lifecycle hook: sleep 5 for connection draining
- TCP probes removed
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Build succeeds:
```bash
cd k8s/dittofs-operator && go build ./...
```

2. Tests pass:
```bash
cd k8s/dittofs-operator && go test ./... -v
```

3. EventRecorder wired:
```bash
grep "Recorder" k8s/dittofs-operator/internal/controller/dittoserver_controller.go | head -5
grep "GetEventRecorderFor" k8s/dittofs-operator/cmd/main.go
```

4. HTTP probes configured:
```bash
grep -A5 "LivenessProbe" k8s/dittofs-operator/internal/controller/dittoserver_controller.go | grep -E "HTTPGet|Path"
```

5. PreStop hook configured:
```bash
grep -A5 "PreStop" k8s/dittofs-operator/internal/controller/dittoserver_controller.go
```
</verification>

<success_criteria>
- DittoServerReconciler has Recorder field wired from main.go via GetEventRecorderFor
- Events emitted for: Created, Deleting, CleanupTimeout, PerconaDeleted, PerconaOrphaned, PerconaNotReady, ConfigUpdated, ReconcileFailed
- LivenessProbe: HTTP GET /health on API port (default 8080)
- ReadinessProbe: HTTP GET /health/ready on API port
- StartupProbe: HTTP GET /health with 30 failure threshold (150s max startup)
- PreStop lifecycle hook: sleep 5 command
- All tests pass, build succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/05-status-conditions-and-lifecycle/05-03-SUMMARY.md`
</output>
