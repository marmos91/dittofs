---
phase: 05-status-conditions-and-lifecycle
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - k8s/dittofs-operator/internal/controller/dittoserver_controller.go
  - k8s/dittofs-operator/api/v1alpha1/dittoserver_types.go
autonomous: true

must_haves:
  truths:
    - "Deleting DittoServer CR triggers finalizer logic before resource deletion"
    - "Owned resources (StatefulSet, Services, ConfigMap) are cleaned up via Kubernetes garbage collection"
    - "When spec.percona.deleteWithServer=true, PerconaPGCluster is deleted with DittoServer"
    - "When spec.percona.deleteWithServer=false (default), PerconaPGCluster is orphaned on deletion"
    - "Cleanup completes within 60-second timeout; after timeout, finalizer is removed regardless"
  artifacts:
    - path: "k8s/dittofs-operator/internal/controller/dittoserver_controller.go"
      provides: "Finalizer handling with cleanup logic and timeout"
      contains: "finalizerName"
    - path: "k8s/dittofs-operator/api/v1alpha1/dittoserver_types.go"
      provides: "DeleteWithServer field in PerconaConfig"
      contains: "DeleteWithServer"
  key_links:
    - from: "dittoserver_controller.go"
      to: "controllerutil"
      via: "AddFinalizer, RemoveFinalizer, ContainsFinalizer"
      pattern: "controllerutil\\.(Add|Remove|Contains)Finalizer"
---

<objective>
Implement finalizers for clean resource cleanup when DittoServer is deleted.

Purpose: Ensure predictable deletion behavior with proper cleanup of owned resources. Support Percona orphaning vs cascade delete based on user preference (R5.2).

Output: Finalizer pattern in reconciler with configurable Percona deletion behavior via spec.percona.deleteWithServer field. 60-second cleanup timeout to prevent stuck Terminating resources.
</objective>

<execution_context>
@/Users/marmos91/.claude/get-shit-done/workflows/execute-plan.md
@/Users/marmos91/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-status-conditions-and-lifecycle/05-RESEARCH.md
@k8s/dittofs-operator/api/v1alpha1/dittoserver_types.go
@k8s/dittofs-operator/internal/controller/dittoserver_controller.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add DeleteWithServer field to PerconaConfig CRD type</name>
  <files>
    k8s/dittofs-operator/api/v1alpha1/dittoserver_types.go
  </files>
  <action>
Add the DeleteWithServer field to the PerconaConfig struct. Find the PerconaConfig struct and add the new field:

```go
// PerconaConfig configures auto-creation of PerconaPGCluster for PostgreSQL metadata store
type PerconaConfig struct {
    // Enabled triggers auto-creation of PerconaPGCluster
    // +kubebuilder:default=false
    Enabled bool `json:"enabled,omitempty"`

    // DeleteWithServer controls whether PerconaPGCluster is deleted when DittoServer is deleted.
    // If true, the PostgreSQL cluster and its data are deleted with the DittoServer.
    // If false (default), the PerconaPGCluster is orphaned and preserved.
    // WARNING: Setting to true will delete all PostgreSQL data when DittoServer is deleted!
    // +kubebuilder:default=false
    // +optional
    DeleteWithServer bool `json:"deleteWithServer,omitempty"`

    // ... rest of the existing fields (Replicas, StorageSize, etc.)
```

Make sure the field is placed right after Enabled to keep related fields together.
  </action>
  <verify>
```bash
cd /Users/marmos91/Projects/dittofs/k8s/dittofs-operator && go build ./...
```
Build succeeds.
  </verify>
  <done>
- PerconaConfig has DeleteWithServer field with default=false
- Field has kubebuilder markers for default and optional
- Warning comment explains data deletion risk
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement finalizer pattern with Percona orphaning/deletion logic</name>
  <files>
    k8s/dittofs-operator/internal/controller/dittoserver_controller.go
  </files>
  <action>
1. Add the finalizer constant at the top of the file, after the imports and before the DittoServerReconciler struct:

```go
const (
    // finalizerName is the finalizer for DittoServer cleanup
    finalizerName = "dittofs.dittofs.com/finalizer"
    // cleanupTimeout is the maximum time to wait for cleanup before force-removing finalizer
    cleanupTimeout = 60 * time.Second
)
```

2. Add a new method to handle deletion. Add this before the Reconcile function:

```go
// handleDeletion processes DittoServer deletion, performing cleanup before allowing deletion to proceed.
// Returns (requeue, error) - if requeue is true, reconciliation should be requeued.
func (r *DittoServerReconciler) handleDeletion(ctx context.Context, dittoServer *dittoiov1alpha1.DittoServer) (bool, error) {
    logger := logf.FromContext(ctx)

    if !controllerutil.ContainsFinalizer(dittoServer, finalizerName) {
        // Finalizer already removed, nothing to do
        return false, nil
    }

    logger.Info("Processing DittoServer deletion", "name", dittoServer.Name)

    // Update phase to Deleting
    dittoServerCopy := dittoServer.DeepCopy()
    dittoServerCopy.Status.Phase = "Deleting"
    if err := r.Status().Update(ctx, dittoServerCopy); err != nil {
        logger.Error(err, "Failed to update phase to Deleting")
        // Continue with cleanup even if status update fails
    }

    // Check how long we've been trying to delete
    deletionTime := dittoServer.DeletionTimestamp.Time
    elapsed := time.Since(deletionTime)

    if elapsed > cleanupTimeout {
        logger.Info("Cleanup timeout exceeded, forcing finalizer removal",
            "elapsed", elapsed, "timeout", cleanupTimeout)
        // Force remove finalizer after timeout
        controllerutil.RemoveFinalizer(dittoServer, finalizerName)
        if err := r.Update(ctx, dittoServer); err != nil {
            return false, err
        }
        return false, nil
    }

    // Perform cleanup
    if err := r.performCleanup(ctx, dittoServer); err != nil {
        logger.Error(err, "Cleanup failed, will retry")
        // Requeue with backoff
        return true, nil
    }

    // Cleanup successful, remove finalizer
    logger.Info("Cleanup complete, removing finalizer")
    controllerutil.RemoveFinalizer(dittoServer, finalizerName)
    if err := r.Update(ctx, dittoServer); err != nil {
        return false, err
    }

    return false, nil
}

// performCleanup handles cleanup of resources that need special handling beyond owner references.
// Owned resources (StatefulSet, Services, ConfigMap) are automatically garbage collected.
// This handles Percona orphaning/deletion based on spec.percona.deleteWithServer.
func (r *DittoServerReconciler) performCleanup(ctx context.Context, dittoServer *dittoiov1alpha1.DittoServer) error {
    logger := logf.FromContext(ctx)

    // Handle Percona cleanup based on deleteWithServer flag
    if dittoServer.Spec.Percona != nil && dittoServer.Spec.Percona.Enabled {
        clusterName := percona.ClusterName(dittoServer.Name)
        pgCluster := &pgv2.PerconaPGCluster{}
        err := r.Get(ctx, client.ObjectKey{
            Namespace: dittoServer.Namespace,
            Name:      clusterName,
        }, pgCluster)

        if err != nil && !apierrors.IsNotFound(err) {
            return fmt.Errorf("failed to get PerconaPGCluster: %w", err)
        }

        if err == nil {
            // PerconaPGCluster exists
            if dittoServer.Spec.Percona.DeleteWithServer {
                // Delete the PerconaPGCluster - it will cascade to PVCs
                logger.Info("Deleting PerconaPGCluster (deleteWithServer=true)",
                    "name", clusterName)
                if err := r.Delete(ctx, pgCluster); err != nil && !apierrors.IsNotFound(err) {
                    return fmt.Errorf("failed to delete PerconaPGCluster: %w", err)
                }
                // Note: Deletion is async, but we proceed since owner reference is being removed
            } else {
                // Orphan the PerconaPGCluster by removing our owner reference
                logger.Info("Orphaning PerconaPGCluster (deleteWithServer=false)",
                    "name", clusterName)

                // Remove owner reference
                var newOwnerRefs []metav1.OwnerReference
                for _, ref := range pgCluster.OwnerReferences {
                    if ref.UID != dittoServer.UID {
                        newOwnerRefs = append(newOwnerRefs, ref)
                    }
                }

                if len(newOwnerRefs) != len(pgCluster.OwnerReferences) {
                    pgCluster.OwnerReferences = newOwnerRefs
                    if err := r.Update(ctx, pgCluster); err != nil {
                        return fmt.Errorf("failed to orphan PerconaPGCluster: %w", err)
                    }
                    logger.Info("PerconaPGCluster orphaned successfully", "name", clusterName)
                }
            }
        }
    }

    // Other owned resources (StatefulSet, Services, ConfigMap) are automatically
    // garbage collected via owner references when DittoServer is deleted.
    // No additional cleanup needed for them.

    return nil
}
```

3. Modify the Reconcile function to handle deletion and add finalizer. At the start of Reconcile, right after getting the dittoServer resource, add:

```go
    // Handle deletion
    if !dittoServer.ObjectMeta.DeletionTimestamp.IsZero() {
        requeue, err := r.handleDeletion(ctx, dittoServer)
        if err != nil {
            return ctrl.Result{}, err
        }
        if requeue {
            return ctrl.Result{RequeueAfter: 5 * time.Second}, nil
        }
        return ctrl.Result{}, nil
    }

    // Add finalizer if not present
    if !controllerutil.ContainsFinalizer(dittoServer, finalizerName) {
        logger.Info("Adding finalizer to DittoServer")
        controllerutil.AddFinalizer(dittoServer, finalizerName)
        if err := r.Update(ctx, dittoServer); err != nil {
            return ctrl.Result{}, err
        }
        // Requeue to continue with reconciliation after finalizer is added
        return ctrl.Result{Requeue: true}, nil
    }
```

4. Add the required import for metav1 if not already present (it should be, but verify):
```go
import (
    // ... existing imports ...
    metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)
```
  </action>
  <verify>
```bash
cd /Users/marmos91/Projects/dittofs/k8s/dittofs-operator && go build ./... && go test ./... -v
```
Build and tests pass.
  </verify>
  <done>
- Finalizer constant defined: "dittofs.dittofs.com/finalizer"
- Cleanup timeout: 60 seconds
- handleDeletion checks for timeout and forces finalizer removal if exceeded
- performCleanup handles Percona orphaning (default) or deletion (when deleteWithServer=true)
- Finalizer added on create, removed after cleanup
- Phase set to "Deleting" during deletion
  </done>
</task>

<task type="auto">
  <name>Task 3: Regenerate manifests and test finalizer logic</name>
  <files>
    k8s/dittofs-operator/config/crd/bases/dittofs.dittofs.com_dittoservers.yaml
    k8s/dittofs-operator/internal/controller/dittoserver_controller_test.go
  </files>
  <action>
1. Regenerate CRD manifests:
```bash
cd k8s/dittofs-operator && make generate manifests
```

2. Update or add a test for the finalizer logic. In dittoserver_controller_test.go, add a test case for deletion handling. Add this test function:

```go
var _ = Describe("DittoServer Finalizer", func() {
    Context("When deleting a DittoServer", func() {
        It("should add finalizer on creation", func() {
            ctx := context.Background()

            // Create a DittoServer
            ds := &dittoiov1alpha1.DittoServer{
                ObjectMeta: metav1.ObjectMeta{
                    Name:      "test-finalizer-" + randString(5),
                    Namespace: "default",
                },
                Spec: dittoiov1alpha1.DittoServerSpec{
                    Storage: dittoiov1alpha1.StorageSpec{
                        MetadataSize: "1Gi",
                        CacheSize:    "1Gi",
                    },
                },
            }

            Expect(k8sClient.Create(ctx, ds)).To(Succeed())

            // Wait for finalizer to be added
            Eventually(func() bool {
                err := k8sClient.Get(ctx, client.ObjectKeyFromObject(ds), ds)
                if err != nil {
                    return false
                }
                return controllerutil.ContainsFinalizer(ds, "dittofs.dittofs.com/finalizer")
            }, timeout, interval).Should(BeTrue())

            // Cleanup
            Expect(k8sClient.Delete(ctx, ds)).To(Succeed())
        })
    })
})
```

Note: The existing test suite structure uses Ginkgo. If the test file uses a different pattern, adapt accordingly. The key is to verify that:
- Finalizer is added on creation
- Resource can be deleted

3. Run tests:
```bash
cd k8s/dittofs-operator && go test ./... -v
```
  </action>
  <verify>
```bash
cd /Users/marmos91/Projects/dittofs/k8s/dittofs-operator && make generate manifests && go test ./... -v
```
Commands succeed:
- CRD YAML contains `deleteWithServer` field
- Tests pass (including any new finalizer tests)
  </verify>
  <done>
- CRD manifest regenerated with deleteWithServer field in spec.percona
- Finalizer test added (or existing tests still pass)
- All tests pass
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Build succeeds:
```bash
cd k8s/dittofs-operator && go build ./...
```

2. Tests pass:
```bash
cd k8s/dittofs-operator && go test ./... -v
```

3. CRD has deleteWithServer field:
```bash
grep -A3 "deleteWithServer" k8s/dittofs-operator/config/crd/bases/dittofs.dittofs.com_dittoservers.yaml
```

4. Finalizer constant exists:
```bash
grep "finalizerName" k8s/dittofs-operator/internal/controller/dittoserver_controller.go
```
</verification>

<success_criteria>
- PerconaConfig struct has DeleteWithServer field (default: false)
- Finalizer constant: "dittofs.dittofs.com/finalizer"
- Reconciler adds finalizer on creation
- handleDeletion processes cleanup before removing finalizer
- performCleanup orphans PerconaPGCluster by default (removes owner reference)
- performCleanup deletes PerconaPGCluster when deleteWithServer=true
- 60-second timeout forces finalizer removal if cleanup hangs
- Phase shows "Deleting" during deletion
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-status-conditions-and-lifecycle/05-02-SUMMARY.md`
</output>
