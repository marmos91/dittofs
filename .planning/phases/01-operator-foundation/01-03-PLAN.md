---
phase: 01-operator-foundation
plan: 03
type: execute
wave: 3
depends_on: ["01-02"]
files_modified:
  - k8s/dittofs-operator/config/default/kustomization.yaml
autonomous: false

must_haves:
  truths:
    - "kubectl apply -f config/samples/dittofs_v1alpha1_dittofs_memory.yaml creates CR"
    - "kubectl get dittofs shows the custom resource"
    - "Operator reconciles CR and creates StatefulSet"
    - "DittoFS pod starts (or enters pending state due to image pull)"
  artifacts:
    - path: "k8s/dittofs-operator/bin/manager"
      provides: "Built operator binary"
  key_links:
    - from: "DittoServer CR"
      to: "StatefulSet"
      via: "controller reconciliation"
      pattern: "OwnerReference"
---

<objective>
Validate the operator end-to-end: deploy to a local cluster, apply sample CR, verify StatefulSet and pod creation.

Purpose: Confirm the operator works correctly after relocation. This is the Phase 1 success criteria validation: CR -> Reconcile -> StatefulSet -> Pod.

Output: Validated operator deployment with evidence of successful reconciliation.
</objective>

<execution_context>
@/Users/marmos91/.claude/get-shit-done/workflows/execute-plan.md
@/Users/marmos91/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/01-operator-foundation/01-RESEARCH.md
@.planning/phases/01-operator-foundation/01-01-SUMMARY.md
@.planning/phases/01-operator-foundation/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Prepare local cluster and deploy CRD</name>
  <files>k8s/dittofs-operator/config/crd/bases/dittofs.dittofs.com_dittoservers.yaml</files>
  <action>
Ensure a local Kubernetes cluster is available and deploy the CRD.

1. Check for available cluster (try in order):
   - `kubectl cluster-info` - check if already connected
   - If using Scaleway: `kubectl config use-context dittofs-demo`
   - If no cluster: `kind create cluster --name dittofs-test` or `minikube start`

2. Deploy the CRD to the cluster:
   ```bash
   cd k8s/dittofs-operator
   make install  # This runs: kubectl apply -f config/crd/bases
   ```

3. Verify CRD is installed:
   ```bash
   kubectl get crd dittoservers.dittofs.dittofs.com
   kubectl api-resources | grep dittofs
   ```

The CRD installation should show:
- dittoservers.dittofs.dittofs.com CRD exists
- Short names: ditto, dittofs
  </action>
  <verify>
Run: `kubectl get crd dittoservers.dittofs.dittofs.com -o name` - returns crd/dittoservers.dittofs.dittofs.com
Run: `kubectl api-resources | grep -i ditto` - shows DittoServer with shortNames
  </verify>
  <done>CRD is installed on cluster, kubectl get dittofs works (returns "No resources found")</done>
</task>

<task type="auto">
  <name>Task 2: Run operator locally and apply sample CR</name>
  <files>k8s/dittofs-operator/config/samples/dittofs_v1alpha1_dittofs_memory.yaml</files>
  <action>
Run the operator locally (outside cluster) and apply the sample CR to trigger reconciliation.

1. In one terminal, run the operator locally:
   ```bash
   cd k8s/dittofs-operator
   make run  # This builds and runs the operator against the cluster
   ```

   The operator will connect to the cluster and watch for DittoServer resources.
   Keep this terminal running.

2. In another terminal (or use background mode), apply the sample CR:
   ```bash
   kubectl apply -f k8s/dittofs-operator/config/samples/dittofs_v1alpha1_dittofs_memory.yaml
   ```

3. Wait a few seconds for reconciliation, then check:
   ```bash
   kubectl get dittofs
   kubectl get statefulset
   kubectl get configmap | grep dittofs
   kubectl get svc | grep dittofs
   ```

Expected results:
- DittoServer CR exists with status
- StatefulSet created with same name as CR
- ConfigMap created with "-config" suffix
- Service created with same name as CR

4. Check the pod status:
   ```bash
   kubectl get pods
   kubectl describe pod <pod-name>
   ```

The pod may be in:
- Running: Image pulled successfully
- Pending: Waiting for PVC
- ImagePullBackOff: Image not accessible (ok for validation - operator still worked)
  </action>
  <verify>
Run: `kubectl get dittofs -o wide` - shows CR with status
Run: `kubectl get statefulset` - shows StatefulSet with READY column
Run: `kubectl get configmap | grep config` - shows ConfigMap
  </verify>
  <done>Operator reconciled CR, created StatefulSet, ConfigMap, and Service</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete operator validation:
1. Operator relocated to k8s/dittofs-operator/
2. RBAC includes secrets permission
3. CRD includes dittofs shortName
4. Sample CR with memory stores
5. Operator reconciled and created resources
  </what-built>
  <how-to-verify>
1. Run these commands and confirm expected output:

   ```bash
   # Verify CRD shortName works
   kubectl get dittofs
   # Expected: Shows dittofs-memory CR or "No resources found"

   # Verify StatefulSet was created
   kubectl get statefulset
   # Expected: Shows dittofs-memory statefulset

   # Verify ConfigMap was created
   kubectl get configmap | grep dittofs
   # Expected: Shows dittofs-memory-config

   # Check pod status
   kubectl get pods
   # Expected: dittofs-memory-0 pod (may be Pending, Running, or ImagePullBackOff)

   # View CR status
   kubectl get dittofs dittofs-memory -o yaml | grep -A20 "status:"
   # Expected: Shows phase, conditions, nfsEndpoint
   ```

2. If pod is in ImagePullBackOff, that's OK - it means the operator worked correctly but the DittoFS image isn't accessible. The key validation is:
   - StatefulSet exists
   - ConfigMap exists with valid config
   - Service exists
   - CR status is updated

3. If you have a working DittoFS image, verify pod reaches Running state.
  </how-to-verify>
  <resume-signal>Type "approved" if validation passes, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
Phase 1 Success Criteria from ROADMAP.md:
1. [x] `kubectl apply -f config/samples/dittofs_v1alpha1_dittofs.yaml` creates a DittoFS CR
2. [x] Operator reconciles CR and creates a StatefulSet with single replica
3. [ ] DittoFS pod starts successfully (hardcoded config, memory stores) - may be blocked by image
4. [x] `kubectl get dittofs` shows the custom resource with basic status
5. [x] Operator RBAC allows creating/managing StatefulSets, Services, ConfigMaps

If pod doesn't start due to image issues, Phase 1 is still considered complete - the operator infrastructure works.
</verification>

<success_criteria>
- CRD installed on cluster
- `kubectl get dittofs` returns results (not error)
- Operator reconciles sample CR without errors
- StatefulSet, ConfigMap, Service created with owner references
- CR status updated with phase and conditions
- Human verification confirms end-to-end flow
</success_criteria>

<output>
After completion, create `.planning/phases/01-operator-foundation/01-03-SUMMARY.md`
</output>
